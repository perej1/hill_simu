%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                            %%
%% thesistemplate.tex version 3.10 (2018/04/24)                               %%
%% The LaTeX template file to be used with the aaltothesis.sty (version 3.10) %%
%% style file.                                                                %%
%% This package requires pdfx.sty v. 1.5.84 (2017/05/18) or newer.            %%
%%                                                                            %%
%% This is licensed under the terms of the MIT license below.                 %%
%%                                                                            %%
%% Copyright 2017-2018, by Luis R.J. Costa, luis.costa@aalto.fi,              %%
%% Copyright 2017-2018 documentation in Finnish in the template by Perttu     %%
%% Puska, perttu.puska@aalto.fi                                               %%
%% Copyright Swedish translations 2017-2018 by Elisabeth Nyberg,              %%
%% elisabeth.nyberg@aalto.fi and Henrik Wallén, henrik.wallen@aalto.fi        %%
%%                                                                            %%
%% Permission is hereby granted, free of charge, to any person obtaining a    %%
%% copy of this software and associated documentation files (the "Software"), %%
%% to deal in the Software without restriction, including without limitation  %%
%% the rights to use, copy, modify, merge, publish, distribute, sublicense,   %%
%% and/or sell copies of the Software, and to permit persons to whom the      %%
%% Software is furnished to do so, subject to the following conditions:       %%
%% The above copyright notice and this permission notice shall be included in %%
%% all copies or substantial portions of the Software.                        %%
%% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR %%
%% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,   %%
%% FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL    %%
%% THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER %%
%% LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING    %%
%% FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER        %%
%% DEALINGS IN THE SOFTWARE.                                                  %%
%%                                                                            %%
%%                                                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                            %%
%%                                                                            %%
%% An example for writting your thesis using LaTeX                            %%
%% Original version and development work by Luis Costa, changes by Perttu     %% 
%% Puska.                                                                     %%
%% Support for Swedish added 15092014                                         %%
%% PDF/A-b support added on 15092017                                          %%
%% PDF/A-2b and PDF/A-3b support added on 24042018                            %%
%%                                                                            %%
%% This example consists of the files                                         %%
%%         thesistemplate.tex (versio 3.10)                                   %%
%%         opinnaytepohja.tex (versio 3.10) (for text in Finnish)             %%
%%         aaltothesis.cls (versio 3.10)                                      %%
%%         kuva1.eps (graphics file)                                          %%
%%         kuva2.eps (graphics file)                                          %%
%%         kuva1.jpg (graphics file)                                          %%
%%         kuva2.jpg (graphics file)                                          %%
%%         kuva1.png (graphics file)                                          %%
%%         kuva2.png (graphics file)                                          %%
%%         kuva1.pdf (graphics file)                                          %%
%%         kuva2.pdf (graphics file)                                          %%
%%                                                                            %%
%%                                                                            %%
%% Typeset in Linux either with                                               %%
%% pdflatex: (recommended method)                                             %%
%%             $ pdflatex thesistemplate                                      %%
%%             $ pdflatex thesistemplate                                      %%
%%                                                                            %%
%%   The result is the file thesistemplate.pdf that is PDF/A compliant, if    %%
%%   you have chosen the proper \documenclass options (see comments below)    %%
%%   and your included graphics files have no problems.
%%                                                                            %%
%% Or                                                                         %%
%% latex:                                                                     %%
%%             $ latex thesistemplate                                         %%
%%             $ latex thesistemplate                                         %%
%%                                                                            %%
%%   The result is the file thesistemplate.dvi, which is converted to ps      %%
%%   format as follows:                                                       %%
%%                                                                            %%
%%             $ dvips thesistemplate -o                                      %%
%%                                                                            %%
%%   and then to pdf as follows:                                              %%
%%                                                                            %%
%%             $ ps2pdf thesistemplate.ps                                     %%
%%                                                                            %%
%%   This pdf file is not PDF/A compliant. You must must make it so using,    %%
%%   e.g., Acrobat Pro or PDF-XChange.                                        %%
%%                                                                            %%
%%                                                                            %%
%% Explanatory comments in this example begin with the characters %%, and     %%
%% changes that the user can make with the character %                        %%
%%                                                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% WHAT is PDF/A
%%
%% PDF/A is the ISO-standardized version of the pdf. The standard's goal is to
%% ensure that he file is reproducable even after a long time. PDF/A differs
%% from pdf in that it allows only those pdf features that support long-term
%% archiving of a file. For example, PDF/A requires that all used fonts are
%% embedded in the file, whereas a normal pdf can contain only a link to the
%% fonts in the system of the reader of the file. PDF/A also requires, among
%% other things, data on colour definition and the encryption used.
%% Currently three PDF/A standards exist:
%% PDF/A-1: based on PDF 1.4, standard ISO19005-1, published in 2005.
%%          Includes all the requirements essential for long-term archiving.
%% PDF/A-2: based on PDF 1.7, standard ISO19005-2, published in 2011.
%%          In addition to the above, it supports embedding of OpenType fonts,
%%          transparency in the colour definition and digital signatures.
%% PDF/A-3: based on PDF 1.7, standard ISO19005-3, published in 2012.
%%          Differs from the above only in that it allows embedding of files in
%%          any format (e.g., xml, csv, cad, spreadsheet or wordprocessing
%%          formats) into the pdf file.
%% PDF/A-1 files are not necessarily PDF/A-2 -compatible and PDF/A-2 are not
%% necessarily PDF/A-1 -compatible.
%% All of the above PDF/A standards have two levels:
%% b: (basic) requires that the visual appearance of the document is reliably
%%    reproduceable.
%% a (accessible) in addition to the b-level requirements, specifies how
%%   accessible the pdf file is to assistive software, say, for the physically
%%   impaired.
%% For more details on PDF/A, see, e.g., https://en.wikipedia.org/wiki/PDF/A
%%
%%
%% WHICH PDF/A standard should my thesis conform to?
%%
%% Primarily to the PDF/A-1b standard. All the figures and graphs typically
%% use in thesis work do not require transparency features, a basic '2-D'
%% visualisation suffices. The font to be used are specified in this template
%% and they should not be changed. However, if you have figures where
%% transparency characteristics matter, use the PDF/A-2b standard. Do not use
%% the PDF/A-3b standard for your thesis.
%%
%%
%% WHAT graphics format can I use to produce my PDF/A compliant file?
%%
%% When using pdflatex to compile your work, use jpg, png or pdf files. You may
%% have PDF/A compliance problems with figures in pdf format. Do not use PDF/A
%% compliant graphics files.
%% If you decide to use latex to compile your work, the only acceptable file
%% format for your figure is eps. DO NOT use the ps format for your figures.

%% USE one of these:
%% * the first when using pdflatex, which directly typesets your document in the
%%   chosen pdf/a format and you want to publish your thesis online,

%% * the second when you want to print your thesis to bind it, or
%% * the third when producing a ps file and a pdf/a from it.
%%
%\documentclass[english, 12pt, a4paper, elec, utf8, a-1b, online]{aaltothesis}
%\documentclass[english, 12pt, a4paper, elec, utf8, a-1b]{aaltothesis}
%\documentclass[english, 12pt, a4paper, elec, dvips, online]{aaltothesis}
\documentclass[english,12pt,a4paper,pdftex,sci,utf8]{aaltothesis} % ITSE LISÄTTY. pdfx.sty vanha.

%% Use the following options in the \documentclass macro above:
%% your school: arts, biz, chem, elec, eng, sci
%% the character encoding scheme used by your editor: utf8, latin1
%% thesis language: english, finnish, swedish
%% make an archiveable PDF/A-1b, PDF/A-2b or PDF/A-3b compliant file: a-1b,
%%                    a-2b, a-3b
%%                    (a normal pdf is produced without the a-*b option)
%% typeset in symmetric layout and blue hypertext for online publication: online
%%            (no option is the default, resulting in a wide margin on the
%%             binding side of the page and black hypertext)
%% two-sided printing: twoside (default is one-sided printing)
%%

\usepackage{bbm}
\usepackage{graphicx}
\usepackage{float}
\usepackage{chngcntr} % Appendixista etuliite figureihin
\usepackage{ctable}

%% Math fonts, symbols, and formatting; these are usually needed
\usepackage{amsfonts,amssymb,amsbsy,amsmath,amsthm}


% Theorems, corollaries and lemmas
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}

%% Change the school field to specify your school if the automatically set name
%% is wrong
% \university{aalto-yliopisto}
% \school{Sähkötekniikan korkeakoulu}

%% Edit to conform to your degree programme
%%
\degreeprogram{Technical Physics and Mathematics}
%%

%% Your major
%%
\major{Mathematics and Systems Analysis}
%%

%% Major subject code
%%
\code{SCI3025}
%%
 
%% Choose one of the three below
%%
\univdegree{BSc}
%\univdegree{MSc}
%\univdegree{Lic}
%%

%% Your name (self explanatory...)
%%
\thesisauthor{Jaakko Pere}
%%

%% Your thesis title comes here and possibly again together with the Finnish or
%% Swedish abstract. Do not hyphenate the title, and avoid writing too long a
%% title. Should LaTeX typeset a long title unsatisfactorily, you mght have to
%% force a linebreak using the \\ control characters.
%% In this case...
%% Remember, the title should not be hyphenated!
%% A possible "and" in the title should not be the last word in the line, it
%% begins the next line.
%% Specify the title again without the linebreak characters in the optional
%% argument in box brackets. This is done because the title is part of the 
%% metadata in the pdf/a file, and the metadata cannot contain linebreaks.
%%
\thesistitle{Asymptotic Properties of the Hill Estimator}
%\thesistitle[Title of the thesis]{Title of\\ the thesis}
%%

%%
\place{Espoo}
%%

%% The date for the bachelor's thesis is the day it is presented
%%
\date{23.8.2018}
%%

%% Thesis supervisor
%% Note the "\" character in the title after the period and before the space
%% and the following character string.
%% This is because the period is not the end of a sentence after which a
%% slightly longer space follows, but what is desired is a regular interword
%% space.
%%
\supervisor{Ph.D  Pauliina Ilmonen}
%%

%% Advisor(s)---two at the most---of the thesis. Check with your supervisor how
%% many official advisors you can have.
%%
%\advisor{Prof.\ Pirjo Professor}
\advisor{M.Sc Matias Heikkilä}
%\advisor{MSc Sarah Scientist}
%%

%% Aaltologo: syntax:
%% \uselogo{aaltoRed|aaltoBlue|aaltoYellow|aaltoGray|aaltoGrayScale}{?|!|''}
%% The logo language is set to be the same as the thesis language.
%%
\uselogo{aaltoRed}{?}
%%

%% The English abstract:
%% All the details (name, title, etc.) on the abstract page appear as specified
%% above.
%% Thesis keywords:
%% Note! The keywords are separated using the \spc macro
%%
\keywords{For keywords choose\spc concepts that are\spc central to your\spc thesis}
%%

%% The abstract text. This text is included in the metadata of the pdf file as well
%% as the abstract page.
%%
\thesisabstract{
Your abstract in English. Keep the abstract short. The abstract explains your 
research topic, the methods you have used, and the results you obtained. In the 
PDF/A format of this thesis, in addition to the abstract page, the abstract text is 
written into the pdf file's metadata. Write here the text that goes into the 
metadata. The metadata cannot contain special characters, linebreak or paragraph 
break characters, so these must not be used here. If your abstract does not contain 
special characters and it does not require paragraphs, you may take advantage of 
the abstracttext macro (see the comment below). Otherwise, the metadata abstract 
text must be identical to the text on the abstract page.
}

%% Copyright text. Copyright of a work is with the creator/author of the work
%% regardless of whether the copyright mark is explicitly in the work or not.
%% You may, if you wish, publish your work under a Creative Commons license (see
%% creaticecommons.org), in which case the license text must be visible in the
%% work. Write here the copyright text you want. It is written into the metadata
%% of the pdf file as well.
%% Syntax:
%% \copyrigthtext{metadata text}{text visible on the page}
%% 
%% In the macro below, the text written in the metadata must have a \noexpand
%% macro before the \copyright special character, and macros (\copyright and
%% \year here) must be separated by the \ character (space chacter) from the
%% text that follows. The macros in the argument of the \copyrighttext macro
%% automatically insert the year and the author's name. (Note! \ThesisAuthor is
%% an internal macro of the aaltothesis.cls class file).
%% Of course, the same text could have simply been written as
%% \copyrighttext{Copyright \noexpand\copyright\ 2018 Eddie Engineer}
%% {Copyright \copyright{} 2018 Eddie Engineer}
%%
\copyrighttext{Copyright \noexpand\copyright\ \number\year\ \ThesisAuthor}
{Copyright \copyright{} \number\year{} \ThesisAuthor}

%% You can prevent LaTeX from writing into the xmpdata file (it contains all the 
%% metadata to be written into the pdf file) by setting the writexmpdata switch
%% to 'false'. This allows you to write the metadata in the correct format
%% directly into the file thesistemplate.xmpdata.
%\setboolean{writexmpdatafile}{false}

%% All that is printed on paper starts here
%%
\begin{document}

%% Create the coverpage
%%
\makecoverpage

%% Typeset the copyright text.
%% If you wish, you may leave out the copyright text from the human-readable
%% page of the pdf file. This may seem like a attractive idea for the printed
%% document especially if "Copyright (c) yyyy Eddie Engineer" is the only text
%% on the page. However, the recommendation is to print this copyright text.
%%
\makecopyrightpage

%% Note that when writting your thesis in English, place the English abstract
%% first followed by the possible Finnish or Swedish abstract.

%% Abstract text
%% All the details (name, title, etc.) on the abstract page appear as specified
%% above.
%%
\begin{abstractpage}[english]
  Your abstract in English. Keep the abstract short. The abstract explains your
  research topic, the methods you have used, and the results you obtained.  
  
  The abstract text of this thesis is written on the readable abstract page as
  well as into the pdf file's metadata via the $\backslash$thesisabstract macro
  (see above). Write here the text that goes onto the readable abstract page.
  You can have special characters, linebreaks, and paragraphs here. Otherwise,
  this abstract text must be identical to the metadata abstract text.
  
  If your abstract does not contain special characters and it does not require
  paragraphs, you may take advantage of the abstracttext macro (see the comment
  below).
\end{abstractpage}

%% The text in the \thesisabstract macro is stored in the macro \abstractext, so
%% you can use the text metadata abstract directly as follows:
%%
%\begin{abstractpage}[english]
%	\abstracttext{}
%\end{abstractpage}



%\newpage


%% Preface
%%
\mysection{Preface}
Simulations were performed using computer resources within the Aalto University School of Science "Science-IT" project.\\

\vspace{5cm}
Otaniemi, 23.8.2018

\vspace{5mm}
{\hfill Jaakko Pere \hspace{1cm}}

%% Force a new page after the preface
%%
\newpage


%% Table of contents. 
%%
\thesistableofcontents


%% Symbols and abbreviations
\mysection{Symbols and abbreviations}

\subsection*{Symbols}

\begin{tabular}{ll}
$x^*=\sup\{x : F(x)<1\}$  & the right endpoint of the distribution $F$ \\
$\gamma$ & extreme value index \\
$F^{\leftarrow}(y) = \inf\{x:F(x) \geq y \}$ & left-continuous inverse \\
U & the left-continuous inverse of $\frac{1}{1-F}$ \\
$\mathbbm{1}(p)=
\begin{cases}
1 , \textrm{if p is true}\\
0, \textrm{otherwise}
\end{cases}$ & indicator function \\
$X_{i,n}$ & $i$:th order statistic \\
$\lambda$ & Lebesque measure \\
$\lim \sup A_n = \bigcap_{k=1}^{\infty} \bigcup_{n=k}^{\infty} A_n$ & limit supremum of a sequence of sets $A_n$ \\
$RV_{\alpha}$ & the set of regularly varying functions with index $\alpha$ \\
$D(G_{\gamma})$ & the maximum domain of attraction of $G_{\gamma}$ \\
$f \sim g$ & $\lim_{x \rightarrow \infty} f(x)/g(x)=1$ \\
\end{tabular}


\subsection*{Abbreviations}

\begin{tabular}{ll}
cdf         & cumulative distribution function \\
i.d.d.     & independent and identically distributed \\
a.s.         & almost surely\\
\end{tabular}


%% \clearpage is similar to \newpage, but it also flushes the floats (figures
%% and tables).
%%
\cleardoublepage

%% Text body begins. Note that since the text body is mostly in Finnish the
%% majority of comments are also in Finnish after this point. There is no point
%% in explaining Finnish-language specific thesis conventions in English.
%% This text will be translated to English soon.
%%
\section{Introduction}

Heavy-tailed distributions appear in many fields of science such as insurance and finance. For example the loss returns of a speculative asset or insurance are often heavy-tailed and in practice the focus is often on risk evaluation. One example of such data set is Danish fire insurance loss data \cite{mcneil}  \cite{resnickFire}, while \cite{resnick}, \cite{deHaan} and \cite{embrechts} contain further examples.

Analyzing the tail is challenging since using classical methods, such as empirical quantiles, it is impossible to extrapolate beyond the available data. This motivates the use of Extreme Value Theory (EVT), that provides a rigorous mathematical framework to study extremes. EVT characterizes the behavior of the distribution's tail and tail estimation is often of high practical importance.

One of the possible estimators for extreme value index is the Hill estimator, which was introduced by Bruce Hill in 1975 \cite{hill} and remains one of the most used tail estimators for heavy-tailed distributions.
In this article we will review asymptotic properties of the Hill estimator and particularly its consistency.

Regularly varying functions form the mathematical foundation for the heavy-tailed distributions and consequently they play an important role in the theory of the Hill estimator. We carefully review their properties in addition to consistency of the Hill estimator. We also examine consistency of the Hill estimator by performing Monte Carlo simulations. Results for asymptotic normality of the Hill estimator are provided but won’t be discussed in detail.

The rest of the article is organized as follows. Section \ref{backround} gives requisites for the proofs and theory of the Hill estimator including properties of heavy tailed functions. Section \ref{hillEst} represents the main result, which is consistency and necessary lemmas for the proof of the consistency. Simulations are presented in Section \ref{simut} and concluding remarks are given in Section \ref{conclusion}. Lastly, all the proofs and figures are found in Appendixes \ref{proofs} and \ref{figures}.

%\begin{definition}
%\begin{equation*}
%\hat{\gamma} = \frac{1}{k} \sum_{i=0}^{k-1} \log(X_{n-1,n}) - \log(X_{n-k,n}), \quad 1 \leq k \leq n-1
%\end{equation*}
%\end{definition}

%% Leave page number of the first page empty
%% 
\thispagestyle{empty}




%% Opinn\"aytteess\"a jokainen osa alkaa uudelta sivulta, joten \clearpage
%%
%% In a thesis, every section starts a new page, hence \clearpage
\clearpage

\section{Backround}
\label{backround}

\subsection{Fisher-Tippett-Gnedenko Theorem}
\label{domains}

Let $X_1, X_2, ..., X_n$ be i.d.d. random variables with a cdf $F$. Consider the  sample maxima $M_n = \max(X_1, X_2, ..., X_n)$. The limiting behavior of $M_n$ is trivial: Since $X_1, X_2,..., X_3$ are i.d.d.
\begin{gather*}
P(\max(X_1, X_2, ... , X_n) \leq x) = P(X_1 \leq x, X_2 \leq x,..., X_n \leq x) \\ = 
P(X_1 \leq x) P(X_2 \leq x) ... P(X_n \leq x)
=F^n(x).
\end{gather*}
Now,
\begin{gather*}
\lim_{n\to\infty} F^n(x) = 
\begin{cases}
0, x < x^* \\
1, x \geq x^*.
\end{cases}
\end{gather*}



To achieve a nondegerate distribution it is necessary to normalize the sample maxima $M_n$. The Fisher-Tippett-Gnedenko Theorem states that with a suitable normalization a nondegenate distribution is obtained \cite{fisher}, \cite{gnedenko}.

\begin{theorem}
There exists real constants $a_n>0$ and $b_n \in \mathbb{R}$ such that 

\begin{equation}
\lim_{n\to\infty} F^n(a_nx + b_n) = G_{\gamma}(ax+b),
\label{fisher}
\end{equation}
where
\begin{equation*}
G_{\gamma}(x)=
\begin{cases}
\exp(-(1 + \gamma x)^{-\frac{1}{\gamma}}), \gamma \neq 0 \\
\exp(-e^{-x}), \gamma = 0,
\end{cases}
\label{mdaEq}
\end{equation*}
for all x with $1+\gamma x > 0$ where $\gamma \in \mathbb{R}$.
\end{theorem}
If F satisfies the equation \ref{fisher} for some $\gamma \in \mathbb{R}$ then it is said that F is in the maximum domain of attraction of $G_{\gamma}$, denoted $F \in D(G_{\gamma})$.

We are especially interested in heavy-tailed distributions, i.e. the case $F \in D(G_{\gamma})$, with $\gamma>0$. It turns out that $F$ being heavy-tailed is equivalent to the function $1-F$ being regularly varying with index $-1/ \gamma$. In other words, if the tail function $1-F$ of a distribution is regularly varying then the distribution $F$ is heavy tailed and vice versa. \cite{deHaan}

\begin{theorem}
Cdf F is in the maximum domain of attraction of the extreme value distribution $G_{\gamma}$ with $\gamma>0$ if and only if $x^*=\infty$ and
\begin{equation}
\lim_{t\rightarrow \infty} \frac{1-F(tx)}{1-F(t)} = x^{-\frac{1}{\gamma}}, x>0.
\label{tail}
\end{equation}
\end{theorem}

In addition, condition \eqref{tail} can be written in different form with the $U$ function \cite{deHaan}.

\begin{corollary}
Condition \ref{tail} is equivalent to
\begin{equation}
\lim_{t \rightarrow \infty} \frac{U(tx)}{U(t)} = x^{\gamma}, x>0.
\label{Utail}
\end{equation}
\end{corollary}

Relation \eqref{Utail} turns out to be easier to work with than \eqref{tail} and thus it is used in furher calculations.
%Above equation implies that U is regularly varying with index $\gamma$ if $F \in D(G_{\gamma>0})$.


\subsection{Regularly Varying Functions}

In Section \ref{domains} we saw that $F \in D(G_{\gamma})$ with $\gamma>0$ and $U$ being regularly varying function are equivalent conditions. Regularly varying functions have some useful properties that are needed for the proof of the Hill estimator's consistency. Let's define regularly varying functions properly \cite{deHaan}:
\begin{definition}
A Lebesque measurable function $f: \mathbb{R}^{+} \rightarrow \mathbb{R}$ that is eventually positive is regularly varying if for some index $\alpha \in \mathbb{R}$,
\begin{equation}
\lim_{x \rightarrow \infty} \frac{f(tx)}{f(t)} = x^{\alpha}, \quad x>0.
\label{regular}
\end{equation}
\label{regularDef}
\end{definition}

If a function $f$  is regularly varying with index $\alpha=0$ then $f$ is said to be slowly varying. One property of regularly varying functions is that all of them can be written in form $f(x)=l(x)x^{\alpha}$ where $l(x)$ is slowly varying function. This supports the intuition that heavy tailed distributions behave like pareto distribution after a high threshold. 



\begin{theorem}
If $f \in RV_{\alpha}$ then the convergence in the equation \ref{regular} is uniform .
\begin{equation*}
\lim_{t \rightarrow \infty} \sup_{x  \in [a,b]} \left| \frac{f(tx)}{f(t)} - x^{\alpha} \right| = 0,
\end{equation*}
for $0<a<b<\infty$.
\label{uniform}
\end{theorem}



With uniform convergence it can be proved that all the regularly varying functions can be represented in certain form:

\begin{theorem}[Karamata's representation theorem]
If $f \in RV_{\alpha}$ then there exists measurable functions $a: \mathbb{R} \rightarrow \mathbb{R^+}$ and $c: \mathbb{R} \rightarrow \mathbb{R^+}$ with
\begin{equation*}
\lim_{t \rightarrow \infty} c(t) = c_0 \  \text{and} \  \lim_{t \rightarrow \infty} a(t) = \alpha
\end{equation*}
and $t_0 \in \mathbb{R^+}$ such that for $t > t_0$
\begin{equation}
f(t) = c(t) \exp \left(\int_{t_0}^{t}  \frac{a(s)}{s} ds \right)
\end{equation}
Conversely, if \ref{karamata} holds, then $f \in RV_{\alpha}$.
\label{karamata}
\end{theorem}

For the proof of the above theorem following lemma about the integrals of the regularly varying functions is needed.

\begin{lemma}
Suppose $f \in RV_{\alpha}$. There exists $t_0 > 0$ such that $f(t)$ is positive and locally bounded for $t \geq t_0$. If $\alpha \geq -1$ then
\begin{equation}
\lim_{t \rightarrow \infty} \frac{tf(t)}{\int_{t_0}^{t}f(s)ds} = \alpha + 1.
\label{>-1}
\end{equation}
If $\alpha<-1$ or $\alpha= -1$ and $\int_{0}^{\infty}f(s)ds<\infty$, then
\begin{equation}
\lim_{t \rightarrow \infty} \frac{tf(t)}{\int_{t}^{\infty} f(s) ds} = -\alpha - 1.
\label{<-1}
\end{equation}
Conversely, if \ref{>-1} holds for $-1\leq \alpha < \infty$ or \ref{<-1} holds for $-\infty<\alpha<-1$, then $f \in RV_{\alpha}$.
\label{karamlemma}
\end{lemma}



The following corollary of the Karamata’s representation theorem will play a key role in the proof of the consistency of the Hill estimator. 

\begin{corollary}
Suppose $f \in RV_{\alpha}$. If $\varepsilon, \delta>0$ are arbitrary, there exists $t_0=t_0(\varepsilon, \delta)$ such that for $t\geq t_0$, $tx \geq t_0$,
\begin{equation*}
(1-\varepsilon)x^{\alpha-\delta}<\frac{f(tx)}{f(t)}<(1+\varepsilon)x^{\alpha+\delta}
\end{equation*}
\label{inequality}
\end{corollary}



\clearpage

\section{Hill Estimator}
\label{hillEst}
\subsection{Consistency}

The following theorem states that Hill estimator is consistent i.e. estimator converges in probability to extreme value index. \cite{hill}


\begin{theorem}
Let $X_1, X_2,...$ be i.d.d. variables with cdf $F_X$. Suppose $F_X \in D(G_{\gamma})$ with $\gamma > 0$. Then as $n \rightarrow \infty$, $k=k(n)  \rightarrow \infty$, $\frac{k}{n} \rightarrow 0$,

\begin{equation*}
\hat{\gamma}_H \xrightarrow{p} \gamma.
\end{equation*}
\label{hillcons}
\end{theorem}

For the proof of the above theorem following lemmas and corollary \ref{inequality} are needed, firstly the Renyi's representation \cite{renyi}.
\begin{lemma}
If $E_1, E_2,...$ are i.d.d. random variables from the standard exponential distribution and $E_{1,n} \leq E_{2,n} \leq ... \leq E_{n,n}$ then for $k \leq n$ we have
\begin{multline*}
%\begin{equation*}
%\begin{split}
\big(E_{1,n}, E_{2,n}, ... , E_{k,n}\big) 
\overset{d}{=} \Big(\frac{E_1^*}{n}, \frac{E_1^*}{n}+\frac{E_2^*}{n-1}, ... , \frac{E_1^*}{n}+\frac{E_2^*}{n-1}+...+ \frac{E_k^*}{n-k+1}\Big),
%\end{split}
%\end{equation*}
\end{multline*}
where $E_1^*,E_2^*,...$ are i.d.d. random variables from standard exponential distribution.
\label{renrep}
\end{lemma}

With Renyi's representation complicated joint distribution of dependent order statistics can be represented with more simple joint distribution of independent random variables. Proof of the Renyi's representation is omitted here.

Secondly the lemma about the order statistics of Pareto distribution is necessary \cite{deHaan}.

\begin{lemma}
Let $Y_1, Y_2, ...$ be i.d.d. random variables from Pareto distribution $F_Y(y)=1-\frac{1}{y}$, $y \geq 0$ and let $Y_{1,n} \geq Y_{2,n} \geq ... \geq Y_{n,n}$ be the nth order statistics. Then with such $k=k(n)$ that $k \rightarrow \infty$, $\frac{k}{n} \rightarrow 0$ as $n \rightarrow \infty$,

\begin{equation*}
\lim_{n\to\infty} Y_{n-k,n} = \infty  \quad  \text{a.s}.
\end{equation*}
\label{asconv}
\end{lemma}

Actually above lemma could be generalized for all unbounded distributions but for our needs Pareto distribution is sufficient.


Last lemma we need says that U(Y) is equal in distribution to X, where Y is random variable from Pareto distribution and X is random variable from some distribution $F_X$.

\begin{lemma}
Let $Y$ be random variable from Pareto distribution $F_Y=1-\frac{1}{y}$, $y \geq 0$ Let X be random variable with cdf $F_X$ then $U(Y) \overset{d}{=} X$.
\label{U}
\end{lemma}




To note there is also converse version of the theorem \ref{hillcons} \cite{mason}. Proof is omitted here.

\begin{theorem}
Let $X_1, X_2,...$ be i.i.d. variables from cdf F. Suppose that for some sequence of integers $k=k(n) \rightarrow \infty$, $k(n)/n \rightarrow 0$ and $k(n+1)/k(n) \rightarrow 1$ as $n \rightarrow \infty$
\begin{equation*}
\hat{\gamma}_H \rightarrow \gamma > 0.
\end{equation*}
Then $F \in D(G_{\gamma})$
\end{theorem}

Furthermore almost sure convergence of Hill estimator is proved in the same article \cite{mason} as above theorem.

{ \color{red}
In addition to first-order regular variation \ref{regularDef} there is a second-order condition for regular variation, which allows to examine the rates of converge of the first-order condition. Second-order regular variation is needed for the asymptotic normality of Hill estimator. We define second-order regular variation for case $\gamma > 0$, since it is sufficient considering the Hill estimator.

\begin{definition}
f is second-order regularly varying function for parameters $\gamma>0$ and $\rho \leq 0$ if for $x>0$
\begin{equation*}
\lim_{t \rightarrow \infty} \frac{\frac{f(tx)}{f(t)}-x^{\gamma}}{A(t)} = x^{\gamma} \frac{x^{\rho}-1}{\rho},
\end{equation*}
where $A$ is a one-signed function with $\lim_{t \rightarrow \infty} A(t)=0$.
\label{2RV}
\end{definition}
}

Lastly we formulate the condition for asymptotic normality for $\hat{\gamma}$ \cite{peng}.

\begin{theorem}
Suppose that cdf $F$ satisfies the second-order condition \ref{2RV} and $k=k(n)$ with $k(n)\rightarrow \infty$, $k(n)/n \rightarrow \infty$ when $n\rightarrow \infty$. Then
\begin{equation*}
\sqrt{k}(\hat{\gamma} - \gamma) \xrightarrow{d} N \left( \frac{\lambda}{1- \rho}, \gamma^2 \right)
\end{equation*}
where
\begin{equation*}
\lim_{t \rightarrow \infty} \sqrt{k}A \left(\frac{n}{k} \right) = \lambda, \quad \lambda \in \mathbb{R}.
\end{equation*}
\label{normality}
\end{theorem}
From theorem \ref{normality} it can be seen that for Hill estimator to be asymptotically normal $U$ of the distribution has to satisfy the second-order regular variation. Furthermore, the bias of the hill Estimator is dependent on the choice of $k(n)$ and on the underlying distribution itself.



\clearpage
\section{Simulations}
\label{simut}

The consistency of the Hill estimator is tested with a Monte Carlo simulation. We simulate from Pareto and Cauchy distributions. Cdf of the Pareto distribution is $F(x)=1-\left( \frac{1}{x} \right)^3, x \geq 1$ and the cdf of the Cauchy distribution is $F(x)=\frac{1}{\pi}\arctan(x) + \frac{1}{2}$. Corresponding extreme value indexes are 1/3 for Pareto distribution and 1 for Cauchy distribution. This can be checked with equation \ref{tail} or \ref{Utail}.We simulate $N$ sets of $n_i$ observations from both distributions where $n_i=100+50(i-1), i=1,2,...,399$. Hence the sample size is a vector from 100 to 20000 with steps of 50. We mark this vector with $\textbf{n}=(100,150,...,20000)$. The number of samples $N$ is set to 2000. So for each $n_i$ we calculate N number of estimates $\hat{\gamma}$ with $k=k(n)=o(n)$. For k we chose $k(n)=\sqrt{n}$, thus the condition $k=o(n)$ is fulfilled. Results are shown in figures \ref{pareto} and \ref{cauchy}. Below is a summary of simulation settings.

\ctable[caption={Simulation settings.}, pos={H}, label={setup}, center]{ccccccc}{}{
\toprule
Figure & Distribution & $\gamma$ & Estimator & $n$ & $N$ & $k(n)$ \\
\midrule
\ref{pareto} & Pareto & 1/3 & Hill & \textbf{n} & 2000 & $\sqrt{n}$ \\
\ref{cauchy} & Cauchy & 1 & Hill & \textbf{n} & 2000 & $\sqrt{n}$ \\
\bottomrule
}

Both resulting graphs are constructed in the same manner. Real value of the extreme value index $\gamma$  is plotted as a dashed line. Black curve represents the medians, red curve 1st quartiles and blue curve 3rd quartiles of the N sized samples of estimates.

In figure \ref{pareto} it seems that with small $n$ convergence is very fast and slows down after a while. This can be seen by looking at the quartiles. At the beginning the quartiles squeeze around $\gamma$ but eventually after about $n=12500$ it is hard to see any kind of convergence.

In figure \ref{cauchy} we can conclude that convergence is fast with small numbers of observations but slows down eventually, as in figure \ref{pareto}. It seems that median is a little further from $\gamma$ than in figure \ref{pareto}. This suggests that for Cauchy distribution larger sample size is needed for accurate estimate for $\gamma$ than for Pareto distribution. In both figures \ref{pareto} and \ref{cauchy} quartiles are equally far away from median which suggests that asymptotical distribution of Hill estimator might be symmetrical.


\clearpage
\section{Conclusion}
\label{conclusion}

We reviewed the proof if the Hill estimator's consistency. Properties of the regularly varying functions played a crucial role in the proof of the consistency. Consistency was also studied with simulations, which also showed that Hill estimator has good finite sample properties. Other properties of the Hill estimator such as asymptotic normality and bias are not in the scope of this article. However, these properties are studied in other articles such as \cite{peng}, \cite{hausler} and \cite{haanResnick}.

Lastly we note that  Hill estimator can be extended in various cases. E.g. There are estimators similar to Hill estimator  for the case $\gamma \in \mathbb{R}$. Examples of these kind of estimators are Pickands estimator \cite{pickands} and Moment estimator \cite{dekkers}. Hill estimator can also be extended to multivariate case \cite{ilmonen}.

\clearpage


%% L\"ahdeluettelo

\phantomsection
\addcontentsline{toc}{section}{\refname}
\bibliographystyle{abbrv}
\bibliography{bib}

%% Appendices
%% If you don't have appendices, remove \clearpage and \thesisappendix below.
\clearpage

\thesisappendix
\counterwithin{figure}{section}

\section{Proofs}
\label{proofs}
\subsection{Proof of Theorem \ref{uniform}}

\begin{proof}

{\color{red}

For a slowly varying function the limit relation \ref{regular} can be written in different form with function $F=\log f(e^x)$:
\begin{equation}
\lim_{t \rightarrow \infty} F(t+x)-F(x) = 0.
\label{F}
\end{equation}
The above argument is true, since
\begin{equation*}
F(t+x)-F(t) = \log f(e^{t+x}) - \log f(e^{t}) = \log \left(\underbrace{\frac{f(e^te^x)}{f(e^t)}}_{\rightarrow 1}\right) \rightarrow 0
\end{equation*}
as $t \rightarrow \infty$. The alternative form for slow variation \ref{F} is used in the proof of the uniform convergence.

}



For the proof it can be assumed that $\alpha=0$. If this isn't the case replace $f(x)$ by $f(x)x^{-\alpha}$. Suppose there exists sequences $t_n \rightarrow \infty$, $x_n \rightarrow 0$ as $n \rightarrow \infty$ such that
\begin{equation*}
\left| \frac{f(t_nx_n)}{f(t_n)} - 1 \right| > \delta
\end{equation*}
for all $n \in \mathbb{N}$ and some $\delta>0$. An equivalent condition can be formulated with function $F(x) = \log f(e^x)$(see equation \ref{F}):
\begin{equation}
\left| F(t_n+x_n) - F(t_n) \right| > \delta
\label{assumption}
\end{equation}
with possibly different $x_n$, $t_n$ and $\delta$. Let's define sets

\begin{align*}
Y_{1,n} = \left\{ \ y \in J: \left| F(t_n+y)-F(t_n) \right| > \frac{\delta}{2} \right\}, \\
Y_{2,n} = \left\{ \ y \in J: \left| F(t_n+x_n)-F(t_n+y) \right| > \frac{\delta}{2} \right\} \quad  \textrm{and} \\
Z_n = \left\{ \ z: \left| F(t_n+x_n)-F(t_n+x_n-z) \right| > \frac{\delta}{2}, x_n-z \in J \right\} \\
= \left\{ z: x_n-z \in Y_{2,n} \right\}
\end{align*}
where $J \subset \mathbb{R}$ is a finite interval. Next we will prove that if the equation \ref{assumption} holds then pointwise convergence $\lim_{t \rightarrow \infty}F(t+x_0)-F(t)=0$ cannot hold. Pointwise convergence does not hold if some $x_0$ is included in infinitely many $Y_{1,n}$. Reason for this is that

\begin{equation}
n \geq n_{\varepsilon} \Rightarrow \left| F(t+x_0) - F(t) \right| < \varepsilon, \forall \varepsilon>0, \exists n_{\varepsilon} \in \mathbb{N}
\label{limit}
\end{equation}
cannot hold if $x_0$ is included in infinitely many $Y_{1,n}$. This can be noticed by comparing equation \ref{limit} and the condition of $Y_{1,n}$. Similarly if $x_0$ is included in infinitely many $Z_n$ then pointwise convergence cannot hold, since the condition in $Z_{n}$ can be written as

\begin{equation*}
\begin{split}
\left| F(\underbrace{t_n+x_n}_{=u_n})-F(\underbrace{t_n+x_n}_{=u_n}\overbrace{-z}^{=x_0}) \right| > \frac{\delta}{2} \\
\Leftrightarrow \left| F(u_n+x_0)-F(u_n) \right| > \frac{\delta}{2}
\end{split}
\end{equation*}
where $u_n \rightarrow \infty$.

Notice that $Y_{1,n} \cup Y_{2,n}=J$, since by the equation \ref{assumption} and triangle inequality we have

\begin{equation*}
\begin{split}
\delta < \left| F(t_n+x_n) - F(t_n) \right| = \left| (F(t_n+x_n)-F(t_n+y)) + (F(t_n+y)-F(t_n)) \right| \\
\leq \left| (F(t_n+x_n)-F(t_n+y)) \right| + \left| (F(t_n+y)-F(t_n)) \right| \\
\Rightarrow \left| (F(t_n+x_n)-F(t_n+y)) \right|>\frac{\delta}{2} \lor \left| (F(t_n+y)-F(t_n)) \right|>\frac{\delta}{2}.
\end{split}
\end{equation*}
Additionally $Y_{1,n}$, $Y_{2,n}$ and $J$ are measurable sets. So by subadditivity of the Lebesque measure we have $\lambda(Y_{1,n}) \geq \frac{\lambda(J)}{2} \lor \lambda(Y_{2,n}) \geq \frac{\lambda(J)}{2}$. By the translation property of the Lebesque measure $\lambda(Z_n)=\lambda(Y_{2,n})$ holds. Thus $\lambda(Y_{1,n}) \geq \frac{\lambda(J)}{2} \lor \lambda(Z_n) \geq \frac{\lambda(J)}{2}$ infinitely often. All $Y_{1,n}$ are subsets of finite interval since $Y_{1,n} \subset J$ for all $n$. Similarly all $Z_n$ are subset of a finite interval since $x_n \rightarrow 0$. Hence by Fatou's lemma \cite{lahiri}:
\begin{equation*}
\begin{split}
\lambda(\lim \sup Y_{1,n}) \geq \lim \sup \lambda(Y_{1,n}) \geq \frac{\lambda(J)}{2}  \quad \lor \\
\lambda(\lim \sup Z_{n}) \geq \lim \sup \lambda(Z_{n}) \geq \frac{\lambda(J)}{2}.
\end{split}
\label{fatouapply}
\end{equation*}
Since at least one of the measures $\lambda(\lim \sup Y_{1,n})$ or $\lambda(\lim \sup Z_{n})$ is greater than zero, we have some $x_0$ that is contained in infinitely many $Y_{1,n}$ or $Z_n$. This was the desired contradiction.
\end{proof}

\subsection{Proof of Lemma \ref{karamlemma}}

\begin{proof}
First we prove the equation \ref{>-1}. Suppose that $f \in RV_{\alpha}$. Then by theorem \ref{uniform} there exists $t_0$ and $c$ such that $f(tx)/t<c$ when $t \geq t_0$, $x \in [1,2]$. Then for $t \in [2^nt_0, 2^{n+1}t_0]$ we have
\begin{equation}
\frac{f(t)}{f(t_0)}=\frac{f(t)}{f(2^{-1}t)}\frac{f(2^{-1}t)}{f(2^{-2}t)} ... \frac{f(2^{-n}t)}{f(t_0)} < c^{n+1}.
\label{fracs}
\end{equation}
Equation \ref{fracs} is true since every fraction can be written as $f(tx)/f(t)$. This implies that for $t\geq t_0$ $f(t)$ is both locally bounded and $\int_{t_0}^{t}f(s)ds<\infty$. Consider a function $F(t) = \int_{t_0}^{t}f(s)ds$.We start by proving that $\lim_{t \rightarrow \infty} F(t) = \infty$ when $\alpha>-1$. First notice that $f(2s) \geq 2^{-1}f(s)$ for sufficiently large $s$. For $n\geq n_0$
\begin{equation}
\int_{2^n}^{2^{n+1}} f(s)ds = 2\int_{2^{n-1}}^{2^{n}} f(2s)ds \geq \int_{2^{n-1}}^{2^n} f(s)ds
\label{varchange}
\end{equation}
by the change on variables. Then by induction we have
\begin{equation}
\int_{2^n}^{2^{n+1}} f(s)ds \geq \int_{2^{n_0}}^{2^{n_0+1}} f(s)ds = C > 0.
\label{induction}
\end{equation}
Thus
\begin{equation}
\int_{2^{n_0}}^{\infty} f(s)ds = \sum_{n=n_0}^{\infty} \int_{2^n}^{2^{n+1}} f(s)ds \geq \sum_{n=n_0}^{\infty} \int_{2^n_0}^{2^{n_0+1}} f(s)ds = \sum_{n=n_0}^{\infty} C = \infty
\label{infinite}
\end{equation}
Next we prove that $F \in RV_{\alpha+1}$ for $\alpha>-1$. Let $\varepsilon>0$ and $t_1=t_1(\varepsilon)$. Then $f(xt)<(1+\varepsilon)x^{\alpha}f(t)$ for $t>t_1$. Since $\lim_{t \rightarrow \infty} F(t)=\infty$,
\begin{equation*}
\frac{F(tx)}{F(t)} = \frac{\int_{t_0}^{tx} f(s)ds}{\int_{t_0}^{t} f(t)ds} \sim \frac{\int_{t_1x}^{tx} f(s)ds}{\int_{t_1}^{t} f(t)ds}=\frac{x\int_{t_1}^{t} f(xs)ds}{\int_{t_1}^{t} f(t)ds} < \frac{x\int_{t_1}^{t}(1+\varepsilon)x^{\alpha} f(s)ds}{\int_{t_1}^{t} f(t)ds} = (1+ \varepsilon)x^{\alpha+1}
\end{equation*}
by the change of variables. A similar lower bound for $F(tx)/F(t)$ can be derived by using $f(xt)<(1-\varepsilon)x^{\alpha}f(t)$ as $t > t_1$. So we have that $F \in RV_{\alpha+1}$ for $\alpha>-1$. In the case $\alpha=-1$ and $F(t) \rightarrow \infty$ same proof applies. If $\alpha=-1$ and $F(t)$ has a finite limit and $F \in RV_0$. Now for all $\alpha$
\begin{equation*}
\begin{split}
\frac{F(xt)-F(t)}{tf(t)} = \frac{1}{tf(t)} \int_{t}^{tx}f(u)du = \frac{t}{tf(t)} \int_{1}^{x} f(ut)du = \int_1^x \frac{f(ut)}{f(t)}du \\
\rightarrow \int_1^x u^{\alpha}du = \frac{x^{\alpha+1}-1}{\alpha+1}, \quad t \rightarrow \infty
\end{split}
\end{equation*}
by the theorem \ref{uniform} and change of variables. On the other hand 
\begin{equation*}
\begin{split}
\frac{F(xt)-F(t)}{tf(t)} = \frac{F(t)}{tf(t)}\left(\underbrace{\frac{F(tx)}{F(t)}}_{\rightarrow x^{\alpha+1}} - 1\right) \rightarrow \frac{x^{\alpha+1}-1}{\alpha+1} \\
\Rightarrow \lim_{t \rightarrow \infty} \frac{tf(t)}{F(t)}= \alpha + 1
\end{split}
\end{equation*}
Now we have proven \ref{>-1}. Next we prove equation \ref{<-1}. Let's define
\begin{equation*}
G(t) = \int_{t}^{\infty} f(s)ds
\end{equation*}
In the case $\alpha<-1$ there exists $\delta>0$ such that $f(2s) \leq 2^{-1-\delta}f(s)$ for sufficiently large s. Now we can prove the finiteness of $\lim_{t \rightarrow \infty} G(t)$ in a similar way as the infinitess of $\lim_{t \rightarrow \infty} F(t)$ in equations \ref{varchange}, \ref{induction} and \ref{infinite}. For sufficiently large $n_1$
\begin{equation*}
\begin{split}
\int_{2^{n}}^{2^{n+1}} f(s)ds = 2 \int_{2^{n-1}}^{2^{n}} f(s)ds \leq 2^{-\delta} \int_{2^{n-1}}^{2^n} f(s)ds \leq \\ ... \leq 2^{-\delta(n-n_1)} \int_{2^{n_1}}^{2^{n_1+1}} f(s)ds = 2^{-\delta(n-n_1)} C'
\end{split}
\end{equation*}
by induction and change of variables. Then
\begin{equation*}
\begin{split}
\int_{2^{n_1}}^{\infty} f(s)ds = \sum_{n=n_1}^{\infty} \int_{2^{n}}^{2^{n+1}} f(s)ds \leq C' \sum_{n=n_1}^{\infty} 2^{-\delta(n-n_1)} \\
=C' \sum_{k=0}^{\infty} \left( \frac{1}{2^{\delta}}\right)^k = \frac{C'}{1-1/2^{\delta}}<\infty,
\end{split}
\end{equation*}
Now rest of the proof is analogous. Next we prove the converse results. Suppose that equation \ref{>-1} holds. Let's define a function
\begin{equation*}
b(t) = t\frac{f(t)}{F(t)}
\end{equation*}
Without loss of generality we may suppose that $f(t)>0$ and $t>0$. Integrating both sides of $b(t)/t=f(t)/F(t)$ we obtain for some real $c_1$ and for all $x>0$
\begin{equation}
\int_{1}^{x} \frac{b(t)}{t}dt = \log F(x) + c_1,
\label{int b/t}
\end{equation}
since by change of variables
\begin{equation*}
\int_{1}^{x} \frac{f(t)}{F(t)}dt = \int_{F(1)}^{F(x)} \frac{1}{u}du = \log F(x) + \underbrace{\log F(1)}_{=c_1}.
\end{equation*}
From the equation \ref{int b/t} we have
\begin{equation*}
F(t) = \exp \left( \int_1^x \frac{b(t)}{t}dt-c_1 \right) =\underbrace{\exp(-c_1)}_{=c} \exp \left( \int_1^x \frac{b(t)}{t}dt\right) =c \exp \left( \int_1^x \frac{b(t)}{t}dt\right).
\end{equation*}
Then by using the definition of f again
\begin{equation}
\begin{split}
f(x)=x^{-1}b(x)F(x)=cb(x)\exp \left( -\int_1^x \frac{1}{t} \right) \exp \left( \int_1^x \frac{b(t)}{t} \right)\\
=cb(x)\exp \left( \int_1^x \frac{b(t)-1}{t}dt\right),
\label{frep}
\end{split}
\end{equation}
for all $x>0$. Hence for all $x,t>0$
\begin{equation*}
\begin{split}
\frac{f(tx)}{f(t)}=\frac{b(tx)\exp \left( \int_1^{tx} \frac{b(s)-1}{s}ds\right)}{b(tx)\exp \left( \int_1^{t} \frac{b(s)-1}{s}ds\right)} = \frac{b(tx)}{b(t)} \exp \left( \int_1^{tx} \frac{b(s)-1}{s}ds - \int_1^{t} \frac{b(s)-1}{s}ds\right) \\
= \frac{b(tx)}{b(t)} \exp \left( \int_{t}^{tx} \frac{b(s)-1}{s}ds\right)
= \frac{b(tx)}{b(t)} \exp \left( \int_{1}^{x} \frac{b(ts)-1}{s}ds\right),
\end{split}
\end{equation*}
by the change of variables. By the assumption (equation \ref{>-1}) $b(t) \rightarrow \alpha + 1$ so $b(tx)/b(t) \rightarrow 1$. For sufficiently large $t$
\begin{equation*}
\exp \left( \int_{1}^{x} \frac{b(ts)-1}{s}ds\right) \approx \exp \left( \int_{1}^{x} \frac{\alpha}{s}ds\right)=\exp \left(\alpha \log x \right) = x^{\alpha}
\end{equation*}
The last statement (equation \ref{<-1} implies that $F \in RV_{\alpha}$) can be proved in a similar way.
\end{proof}

\subsection{Proof of Theorem \ref{karamata}}

\begin{proof}
Suppose $f \in RV_{\alpha}$. The function $t^{-\alpha}f(t)$ is slowly varying and
\begin{equation*}
t^{-\alpha}f(t) = cb(t) \exp \left( \int_{1}^{t} \frac{b(s)-1}{s}ds \right)
\end{equation*}
by the equation \ref{frep}. Now by lemma \ref{karamlemma} $b(t) \rightarrow 1$ and function $t^{-\alpha}f(t)$ has the representation as in theorem \ref{karamata} with $a(t)=b(t)-1$ and $c(t)=cb(t)$. Then
\begin{equation*}
f(t) = c(t)t^{\alpha} \exp \left(  \int_{t_0}^{t} \frac{a(s)}{s}ds  \right)
\end{equation*}
Notice that we can write $t^{\alpha}$ as $\exp \left(  \int_{1}^{t} \frac{\alpha}{s}ds  \right)$. Then $f$ has the form
\begin{equation*}
\begin{split}
f(t) = c(t) \exp \left(  \int_{t_0}^{t} \frac{a(s)}{s}ds + \int_{1}^{t} \frac{\alpha}{s}ds  \right) \\
= c(t) \exp \left(  \int_{t_0}^{t} \frac{a(s)+\alpha}{s}ds + \int_{1}^{t_0} \frac{\alpha}{s}ds  \right)\\
= c(t) \exp \left(  \int_{t_0}^{t} \frac{a(s)+\alpha}{s}ds \right) \exp \left( \log t_0^{\alpha}  \right)
\end{split}
\end{equation*}
\begin{equation}
= \underbrace{t_0^{\alpha}c(t)}_{=c'} \exp \left(  \int_{t_0}^{t} \frac{\overbrace{a(s)+\alpha}^{=a'}}{s}ds \right)
\label{fkaramata}
\end{equation}
From the equation \ref{fkaramata} it can be seen that $f(t)$ has the same representation as in the theorem \ref{karamata} when $a$ is replaced by $a'$ and $c$ is replaced by $c'$.
\end{proof}

\subsection{Proof of Corollary \ref{inequality}}

\begin{proof}
By the theorem \ref{karamata}
\begin{equation*}
\frac{f(tx)}{f(t)}=\frac{c(tx)}{c(t)}\exp \left(\int_1^x \frac{a(st)}{s}ds \right)
\end{equation*}
The function c(t) converges to a constant. Hence $c \in RV_0$ so $c(tx)/c(t)\rightarrow 1$ as $t \rightarrow \infty$. Furthermore, $a(s) \rightarrow \alpha$ as $t \rightarrow \infty$. Now we can choose such a $t_0$ that $\alpha-\delta<a(st)<\alpha-\delta$ and $1-\varepsilon<\frac{c(tx)}{c(t)}<1+\varepsilon$. This implies that
\begin{equation*}
\begin{split}
(1-\varepsilon)\int_1^x \frac{\alpha-\delta}{s}ds<\frac{f(tx)}{f(t)}<(1+\varepsilon)\int_1^x \frac{\alpha+\delta}{s}ds \\
\Rightarrow (1-\varepsilon)\exp \left( \log \left( x^{\alpha-\delta} \right) \right)<\frac{f(tx)}{f(t)}<(1+\varepsilon)\exp \left( \log \left( x^{\alpha+\delta} \right) \right) \\
\Rightarrow (1-\varepsilon)x^{\alpha-\delta}<\frac{f(tx)}{f(t)}<(1+\varepsilon)x^{\alpha+\delta}
\end{split}
\end{equation*}
\end{proof}


\subsection{Proof of Lemma \ref{asconv}}

\begin{proof}
Let us assume that $Y_{n-k,n} < r$ for some $r > 0$ infinitely often. In other words
\begin{equation*}
\frac{k}{n} = \frac{1}{n} \sum_{i=1}^{n} \mathbbm{1}(Y_i>Y_{n-k,n}) > \frac{1}{n} \sum_{i=1}^{n} \mathbbm{1}(Y_i>r).
\end{equation*}

Now the left side of the equation converges to zero, since
\begin{equation*}
\lim_{n\to\infty} \frac{1}{n} \sum_{i=1}^{n} \mathbbm{1}(Y_i>Y_{n-k,n}) = \lim_{n\to\infty} \frac{k}{n} =0.
\end{equation*}

But the right side converges to $1/r$ almost surely, since

\begin{equation*}
\frac{1}{n} \sum_{i=1}^{n} \mathbbm{1}(Y_i>r) \xrightarrow{a.s} P(Y_i>r) = 1-F_Y(r) = \frac{1}{r}
\end{equation*}
by the strong law of large numbers \cite{rosenthal}.
So the assumption cannot hold which implies that

\begin{equation*}
P(\lim_{n\to\infty} Y_{n-k,n} = \infty)=1.
\end{equation*}
\end{proof}

\subsection{Proof of Lemma \ref{U}}

\begin{proof}
Let's study the condition $U(Y) \leq a, a \in \mathbb{R} $.
\begin{equation*}
\begin{split}
U(Y) \leq a \\
\Leftrightarrow \inf\big\{x: \frac{1}{1-F_X(x)} \geq Y\big\} \leq a
\end{split}
\end{equation*}
\begin{equation}
\Leftrightarrow \inf\big\{x: 1 - \frac{1}{Y} \leq F_X(x)\big\} \leq a
\label{infeq}
\end{equation}


Let $S=\big\{x: 1 - \frac{1}{Y} \leq F_X(x)\big\}$ and $b = \inf S$. Notice that F is increasing and right-continuous, since F is a cdf. So S is an interval of form $[b,\infty)$ or $(b, \infty)$, since F is increasing. Let's define a sequence $x_n=b+\frac{1}{n}, n\in \mathbb{N}$. Notice that $x_n \rightarrow b$ and $x_n \in S$ for all $n$. Now right-continuity implies that $b \in S$ i.e $S$ is an interval $[b, \infty)$. Additionally $a \in S$ since $a\geq b$ so $a$ satisfies the condition $1-\frac{1}{Y} \leq F(a)$. Therefore the equation \ref{infeq} implies
\begin{equation*}
U(Y) \leq a \Leftrightarrow 1 - \frac{1}{Y} \leq F_X(a) \Leftrightarrow Y \leq \frac{1}{1-F(a)},
\end{equation*}
So now from the cdf of U(Y) we have
\begin{equation*}
\begin{split}
F_{U(Y)} = P(U(Y) \leq x) = P\Big(Y \leq \frac{1}{1-F_X(x)}\Big) = F_Y\Big(\frac{1}{1-F_X(x)}\Big) \\
= 1-\Big(\frac{1}{1-F_X(x)}\Big)^{-1} =F_X(x).
\end{split}
\end{equation*}
\end{proof}

\subsection{Proof of Theorem \ref{hillcons}}

\begin{proof}

$F \in D(G_{\gamma>0})$ is equivalent to the fact that $U \in RV_{\gamma}$ i.e.

\begin{equation*}
\lim_{t\to\infty} \frac{U(tx)}{U(t)} = x^{\gamma}.
\end{equation*}

From the uniform convergence of the regularly varying functions follows that for $x>1$ and $t \geq t_0$,

\begin{equation*}
(1-\varepsilon) x^{\gamma - \delta} < \frac{U(tx)}{U(t)} < (1+\varepsilon) x^{\gamma + \delta},
\end{equation*}

for all $\varepsilon>0$ and $\delta>0$. By taking natural logarithm from both sides of the equation above, it can be written as

\begin{equation}
\begin{split}
\log(1 - \varepsilon) + (\gamma - \delta) \log(x) < \log(U(tx)) - \log(U(t)) \\
< \log(1 + \varepsilon) + (\gamma + \delta) \log(x).
\end{split}
\label{logRV}
\end{equation}

If $Y_1, Y_2,...$ are i.d.d random variables from Pareto distribution with cdf $F_Y(y) = 1 - \frac{1}{y}$ then $U(Y_i)  \overset{d}{=} X_i$  as stated in lemma \ref{U}. Hence it is sufficient to prove the result for $ \hat{\gamma}_H =  \frac{1}{k} \sum_{i=0}^{k-1} \log(U(Y_{n-i,n})) - \log(U(Y_{n-k,n})) $. For $t = Y_{n-k,n}$ and $x =\frac{Y_{n-i,n}}{Y_{n-k,n}}$ equation \ref{logRV} has the form


\begin{equation}
\begin{split}
\log(1 - \varepsilon) + (\gamma - \delta) \log\Big(\frac{Y_{n-i,n}}{Y_{n-k,n}}\Big) < \log(U(Y_{n-i,n})) - \log(U(Y_{n-k,n})) \\
< \log(1 + \varepsilon) + (\gamma + \delta) \log(\frac{Y_{n-i,n}}{Y_{n-k,n}}).
\end{split}
\label{log}
\end{equation}

Notice that we can replace t with $Y_{n-k,n}$ because we can always find some $n_0$ such that $Y_{n_0-k,n_0} \geq t_0$ according to lemma \ref{asconv}. Furthermore, $Y_{n-i,n}$ is greater than $Y_{n-k,n}$ always when $i<k$. Therefore x can be replaced with $\frac{Y_{n-i,n}}{Y_{n-k,n}}$.

Equation \ref{log} applies for every $i = 0,1,2,..., k-1$. Thus we can write

\begin{equation*}
\begin{split}
\log(1 - \varepsilon) + (\gamma - \delta) \frac{1}{k} \sum_{i=0}^{k-1} \log\Big(\frac{Y_{n-i,n}}{Y_{n-k,n}}\Big) < \frac{1}{k} \sum_{i=0}^{k-1} \log(U(Y_{n-i,n})) - \log(U(Y_{n-k,n})) \\
< \log(1 + \varepsilon) + (\gamma + \delta) \frac{1}{k} \sum_{i=0}^{k-1} \log\Big(\frac{Y_{n-i,n}}{Y_{n-k,n}}\Big).
\end{split}
\end{equation*}

The term in the middle is the hill estimator $\hat{\gamma}_H$, hence above becomes

\begin{equation*}
\begin{split}
\log(1 - \varepsilon) + (\gamma - \delta) \frac{1}{k} \sum_{i=0}^{k-1} \log\Big(\frac{Y_{n-i,n}}{Y_{n-k,n}}\Big) < \hat{\gamma}_H \\
< \log(1 + \varepsilon) + (\gamma + \delta) \frac{1}{k} \sum_{i=0}^{k-1} \log\Big(\frac{Y_{n-i,n}}{Y_{n-k,n}}\Big).
\end{split}
\end{equation*}

Now it is sufficient to only prove that 

\begin{equation*}
\frac{1}{k} \sum_{i=0}^{k-1} \log\Big(\frac{Y_{n-i,n}}{Y_{n-k,n}}\Big) \xrightarrow{p} 1.
\end{equation*}

$\log(Y_i)$ has a standard exponential distribution, since 
\begin{equation*}
\begin{split}
F_{\log(Y_i)}(x) = P(\log(Y_i) < x) = P(e^{\log(Y_i)} < e^x) = P(Y_i < e^x) = F_Y(e^x) = 1 - {e^{-x}}.
\end{split}
\end{equation*}

Therefore we can write
\begin{equation*}
\frac{1}{k} \sum_{i=0}^{k-1} \log\Big(\frac{Y_{n-i,n}}{Y_{n-k,n}}\Big) = \frac{1}{k} \sum_{i=0}^{k-1} E_{n-i,n} - E_{n-k,n},
\end{equation*}
where $E_1, E_2,...$ are i.d.d. random variables from standard exponential distribution. Now Renyi's representation \ref{renrep} implies

\begin{equation*}
\begin{split}
\big\{E_{n-i,n} - E_{n-k,n}\big\}_{i=0}^{k-1} \\ 
\overset{d}{=} \bigg\{\Big( \frac{E_1^*}{n} + \frac{E_2^*}{n-1}+...+ \frac{E_{n-(i+1)}^*}{n-(n-(i+1))+1} + \frac{E_{n-i}^*}{n-(n-i)+1} \Big) \\
- \Big(\frac{E_1^*}{n} + \frac{E_2^*}{n-1}+...+\frac{E_{n-k}^*}{n-(n-k)+1}\Big)\bigg\}_{i=0}^{k-1} \\
= \bigg\{\frac{E_{n-i}^*}{i+1} + \frac{E_{n-(i+1)}^*}{i+2} +...+ \frac{E_{n-(k-2)}^*}{k-1} + \frac{E_{n-(k-1)}^*}{k}\bigg\}_{i=0}^{k-1} \\
\overset{d}{=} \big\{E_{k-i,k}\big\}_{i=0}^{k-1}.
\end{split}
\end{equation*}

Consequently we have

\begin{equation*}
\frac{1}{k} \sum_{i=0}^{k-1} \log\Big(\frac{Y_{n-i,n}}{Y_{n-k,n}}\Big) \overset{d}{=} \frac{1}{k} \sum_{i=0}^{k-1} E_{k-i,k} = \frac{1}{k} \sum_{i=0}^{k-1} E_i \xrightarrow{p} E[E_i] = 1
\end{equation*}

by the weak law of large numbers \cite{rosenthal}. Notice that the expected value of a standard exponential is one.



\end{proof}

\section{Figures}
\label{figures}

\begin{figure}[H]
\begin{center}
\includegraphics[width=\textwidth]{pareto.pdf}
\caption{Results of Monte Carlo simulation from Pareto distribution.}
\label{pareto}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[width=\textwidth]{cauchy.pdf}
\caption{Results of Monte Carlo simulation from Cauchy  distribution.}
\label{cauchy}
\end{center}
\end{figure}




\end{document}
